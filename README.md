# File-based workflows for the DoIt automation tool
The goal of this project is to create a library of file mapping classes that provide `action`, `file_dep` and `target` parameters for [DoIt][1] tasks. The mappers allow specifying tasks that rely on globs and file name mapping rather than having to explicity name every file dependency and every target. This is for text and data processing tasks that happen in several stages where data is assembled, converted, filtered and merged.

The classes are inspired by concepts in the build tools [Ant][2] and [Ruffus][3].

## FileMapper usage
A typical DoIt Python task calls a function with a list of target files:

```python
def task_convert_to_json():
    def process_files(targets):
        for t in target:
            source = target.replace(".json", ".csv")
            # read source file, convert to json, write to target file
    return {
        "actions": [process_files],
        "targets": ["file1.json", "file2.json"]
    }
```

A file mapper produces a "source" file for every target file and vice versa. In the example above you only have two target files - but what if you had hundreds, where you don't know their names beforehand? This is where the file mappers come in:

```python
from doitfilemappers import GlobMapper

def task_convert_to_json():
    def process_file(in_file, out_file):
        with in_file.open("r") as _in, out_file.open("w") as _out:
            # read from _in, process data, write to _out
    mapper = GlobMapper("src/*.csv", process_file, pattern="dst/*.json")
    return mapper.get_task()
```

The `get_task` method of the mapper will return the task dictionary with the ` actions`, `targets` and `file_dep` keys generated by the mapper. `actions` is a callable generated by the mapper using the `callback` parameter.

The callback you provide to the mapper must alwways have two parameters - one for the source file and one for target file. Both paramters will be [`pathlib.Path`][5] instances. The callback will be called for every source/target pair of the mapper. The targets provided by DoIt are _ignored_.

### Mapper constructor parameters
The following parameters are common for all mappers
- `src`: Designate which source files should be selected. This can either be a glob string that can be used by [`pathlib.Path.glob`][4] or a list of Path instances. Defaults to all files (`*`).
- `callback`: A callable with `input_file`, `output_file` parameters. For command line tasks this can also be a string with `%(source)s` and `%(target)s` placeholders.
- `in_path`: Operating directory. The glob expression / Path items  in `src` will be evaluated in the context of this path. If `in_path` is absolute, the generated targets will be absolute too. Otherwise they will be relative. Defaults to `.` (current directory).
- `file_dep`: If true, `get_task` creates a `file_dep` key with the source files from the mapper. For most mappers it is true.
- `allow_empty_map`: See "Dealing with empty maps". Defaults to false.
- `error_handling`: A tuple of handled exceptions and an error handler callable. If your callable raises an exeception, the error handling will be used. See "Handling exceptions". By default, exceptions raised in your callback will be undhandled.

All parameters have default values and can be left out.

### Additional task parameters
If you want to have additional keys in the task dictionary returned by `get_task`, e.g. `uptodate`, `basename`, `title`, etc., you can provide them as a parameter to `get_task` or to the mapper constructor. All dictionary values except for `actions`, `targets` and `file_dep` will be left unchanged.

```python
mapper = GlobMapper("*_foo.txt", process_file, "*bar.txt",
    task={"basename":"foo", "uptodate":False}
)
return mapper.get_task({"basename":"bar"}) # "bar" will override "foo"
```

Using the task constructor parameter is important for chained tasks (see below) where you can't access the returned task directly.

### Callback return value
By default DoIt execution will stop when a task returns `False`. If your `callback` function returns `False` for a source/target pair, the generated action will also return `False`. However, all source/target pairs will be iterated. If you want to stop at an error immediately, you must raise an exception. If you have a custom error handling (see below), make sure that the error handling does not interfere.

### Multiple dependent mappers
If you are building a chain of mappers where the output files (targets) of one processing step become the input (sources) of the next step, you can't use a glob expression for the `src` parameter in the following mappers after the first because the files don't exist yet. Instead, you must set the `src` of each task after the first to the `target` output of the preceding task. The ChainedMapper (see below) does that for you.

### Error handling
By default, if an exception occurs in your callback, the execution of the task will stop. With the `error_handling` parameter you can catch exceptions:

```python
def cautious_converter(_in, _out):
    if _out.exists():
        throw IOError("{} already exists!".format(_out))
    # do conversion here

def handle_existing_file(ex):
    print ex.message

mapper = GlobMapper("*.jpg", cautious_converter, replace="*.png",
   error_handling=((IOError), handle_existing_file) 
)
```

As you can see, `error_handling` is a tuple with a set of handled exception classes and a callable that will do something with the exceptions. All exceptions you don't specify will still stop the execution.

### Using the map without creating a task
If you just want to use the file mapping, call the `get_map` method of the mapper. It will return a list of tuples where the first item of each tuple is the source file and the second item of each tuple is the target.

```python
mapper = GlobMapper("*.jpg", replace="*.png") # look ma, no callback!
jpg2png_map = mapper.get_map()
for m in jpg2png_map:
    source = m[0]
    target = m[1]
    print "{} -> {}".format(source, target)
```

If you're interested in separating source and target lists, use the `zip` function:

```python
mapper = GlobMapper("*.jpg", replace="*.png")
jpg2png_map = mapper.get_map()
sources, targets = zip(*jpg2png_map)
print "List of targets:"
print "\n".join(targets)
```

### Using mappers with commandline tasks

If you want to execute a command for every source/target file pair, use a string with placeholders as the callback parameter:

```python
def task_switch_pet():
    cmd = "sed s/dog/cat/ %(source)s > %(target)s"
    mapper = GlobMapper("*_dogs.csv", callback=cmd, replace="*_cats.csv")
    return mapper.get_task()
```

If you want to use the whole list of source or target files, your must build the action yourself:

```python

def task_combine_oo_files_except_moo():
    mapper = RegexMapper(search=r"^[^m]oo$") # match files like "foo" and "goo"
    oo_map = mapper.get_map()
    sources, targets = zip(*oo_map)
    return {
        'actions': ["cat %s > no_moo" % " ".join(targets)],
        'targets': targets
    }
```

This example is a bit contrived because most of the time you'd rather use a command line glob instead of a FileMapper class.

### Decorators for your callback function

#### `@open_files`
If you'd rather work with open files instead of opening and closing them yourself, you can use the `@open_files` decorator:

```python
@open_files
def process_file(in_file, out_file):
    data = in_file.read()
    # process data
    out_file.write(data)
```

Normally the input file is opened in read mode, the output file is opened in write mode. You can change the modes with the `in_mode` and `out_mode` parameters for `@open_file`.

#### `@open_files_with_merge`
This decorator works like `@open_files` except it tracks which target files have already been opened. Files that were opened before, are opened in append mode (`a`). You can customize the modes with the  `in_mode`, `out_mode` and `out_append_mode` parameters.

#### `@track_file_count`
If you want to keep track of the number of files that were processed, use the `@track_file_count` decorator and a `file_count` parameter in your callback:

```python
@track_file_count
def process_file(in_file, out_file, file_count=0):
    if file_count > 99:
        raise RuntimeError("Too many files, I quit!")
```

### Dealing with empty maps
An empty map means that the source files are missing, your glob expression for `src` is wrong or the mapper filtered the file names (can happen with GlobMapper and RegexMapper). In most cases this means the task and all tasks depending on it should not continue, so the default behavior of mappers is to raise an exception if the map is empty.

You can change the default behavior by setting `allow_empty_map` to `True`. You can then provide custom `actions` and `targets` keys to `get_map` do do something else when the map is empty:

```python
from __future__ import print_function

def task_report_missing_foo():
    def report_missing(targets):
        print("WARNING: We're out of 'foo' files!", file=sys.stderr)
    mapper = GlobMapper("*foo", process_foo, "*bar", allow_empty_map=True)
    return mapper.get_task({
        "actions": [report_missing],
        "targets": ["missing_foo"]
    })
```

If you don't provide an `actions` key, the task will simply do nothing. A dummy action is created that just returns `True`. 

## Types of Mappers
### IdentityMapper
This simple mapper returns all files found by the `src` glob as targets and has no `file_dep` (because that would create a cyclic dependency). 

The IdentityMapper is useful for processing files in-place or processing files without changing them.

### GlobMapper
The GlobMapper uses a single asterisk to define a simple replacement pattern.

```python
def task_json2html():
    def process_file(in_file, out_file):
        # do stuff here
    mapper = GlobMapper("*.json", process_file, "*.html")
    return mapper.get_task()
```

The asterisk in the search expression (by default the `src` parameter) is a wildcard expression that matches at least one character. The asterisk in the replace string is the placeholder for everything matched by the wildcard.

If your `src` parameter contains a single file name, a directory glob like `**/*.json`, multiple asterisks like `*.txt*` or complex globs like `ba[rz].txt` you **must** provide an additional replacement pattern parameter that contains a single asterisk. 

```python
mapper = GlobMapper("**/*.json", process_file, "*.html", "*.json")
```

If a single asterisk is not sufficient for your replacement needs, use `RegexMapper` instead.

**Warning:** Some patterns will create the same target name for different source names which may lead to overwriting the target. If you want to append instead, use `@open_files_with_merge`.

### RegexMapper

The RegexMapper uses a regular expression to allow for more complex filename transformations.

```python
def rename_file(_in, _out):
        _in.replace(_out)

def task_move_files():
    """ Rename files named like "Foo_Bar.txt" to "Bar-Foo.txt" """
    mapper = RegexMapper("*.txt", rename_file, r"^(\w+)_(\w+)", r"\2-\1")
    return mapper.get_task()
```

You can set all the usual regular expression flags by using the `flags` parameter:

```python
import re

def task_move_files():
    # match TXT and txt files
    mapper = RegexMapper("*", rename_file
        search=r"^(.*)\.txt",
        replace=r"\1-processed.txt",
        flags=re.IGNORECASE
    )
    return mapper.get_task()
```

By default, the RegexMapper will only return source files that match the search expression. You must set the parameter `ignore_nonmatching` to `False` to include source files that do not match the search expression. You should set `file_dep` to `False` in this case to avoid circular references for unchanged files.

```python
def task_process_text():
    """ 
    Process only CSV and text files.
    All other files will keep their name and show up unchanged
    in the targets list.
    """
    def process_text(_in, _out):
        if _in.suffix() == ".txt":
            # process text file
        elif _in.suffix() == ".csv":
            # process CSV file

    mapper = RegexMapper("*", process_text, 
        search=r"^(.*)\.(txt|csv)$",
        replace=r"\1-processed.\2",
        ignore_nonmatching=False,
        file_dep=False
    )
    return mapper.get_task()
```

**Warning:** Some patterns will create the same target name for different source names which may lead to overwriting the target. If you want to append instead, use `@open_files_with_merge`.

### MergeMapper
The MergeMapper returns the same target file name for all source names.

When using MergeMapper you have to open the output file for appending (mode `a`) instead of opening it while truncating it (mode `w`). This can be a problem because if the target file exists from a previous task run, the content from the source files will be appended to it - not a desired behavior in most cases. To avoid a separate task where you delete the target file before first opening it, use the `@open_files_with_merge` decorator which keeps track of the files, opens the first one with mode `w` and all following files with mode `a`.

```python
def task_combine_reports():
    @open_files_with_merge()
    def process_csv(_in, _out):
        data = _in.read()
        # process data
        _out.write(data)
    mapper = MergeMapper("*.csv", process_csv, "finished/combined.csv")
    return mapper.get_task()
```

### CompositeMapper
The CompositeMapper returns the combined map of several mappers. It has no `src` parameter. 

```python
def task_convert_images():
    def convert_img(image_in, image_out):
        # do some processing here
    sub_mappers = [
        GlobMapper("*.jpg", replace="*_thumb.jpg"),
        GlobMapper("*.jpeg", replace="*_thumb.jpg")
    ]
    mapper = CompositeMapper(sub_mappers, convert_img)
    return mapper.get_task()
```

The example shows that you can omit the `callback` parameter for the sub-mappers, because only the callback of the CompositeMapper will be executed.

Note that the generated map may contain the same source and/or target files multiple times. You must then write your callback in way that can avoids processing the same source file multiple times or overwriting the same target file.

### ChainedMapper
The ChainedMapper chains multiple mappers together, using the target files of each mapper as the source files for the next mapper. The `src` parameter of the ChainedMapper is used as the initial `src` for the first sub-mapper in the chain.

If you want each action of the sub-mappers executed, you must leave the `callback` parameters of ChainedMapper empty:

```python
def rename_file(_in, _out):
        _in.replace(_out)

def task_convert_images():
    def convert_img(image_in, image_out):
        # do some processing here
    # src param ("*") in the following mappers is just a dummy and will
    # be overwritten by the ChainedMapper
    my_sub_mappers = [
        # Remove non-alphanumeric chars in file name
        RegexMapper("*", rename_file, r"[^\w_]", r"_",
            ignore_nonmatching=False),
        # Restore the suffix (dot was replaced be previous step)
        RegexMapper("*", rename_file, r"_jpg$", r".jpg"),
        #  Create Thumbnails
        GlobMapper("*", convert_img, replace="*_thumb.jpg", "*.jpg")
    ]
    mapper = ChainedMapper("*.jpg", sub_mappers=my_sub_mappers)
    return mapper.get_task()
```

If the `callback` parameter of the ChainedMapper is set, the callbacks of the chained sub-mappers will _not_ be executed. Instead, only the map will be generated and the callback of the ChainedMapper will be executed. This is useful for complex mapping types that require multiple steps when generating the final mapping. The generated `file_dep` will be the source files of the _first_ sub-mapper.

```python
def cleanup_file_names():
    # src param is left out since it will be overwritten by ChainedMapper
    # callback param is left out since it won't be called.
    my_sub_mappers = [
        RegexMapper(search=r"[^\w_]", replace=r"_", ignore_nonmatching=False)
        RegexMapper(search=r"^_", replace=r"", ignore_nonmatching=False)
        RegexMapper(search=r"_jpg$", replace=r".jpg")
    ]
    mapper = ChainedMapper("*.jpg", rename_file, sub_mappers=my_sub_mappers)
    return mapper.get_task()
```


## Creating your own mappers

Creating your own mappers is easy - just subclass `BaseMapper` and implement the `_create_map` method:

```python
import pathlib

class LowercaseMapper(BaseMapper):
    def _create_map(self, src):
        return [(s, pathlib.Path(str(s).lower())) for s in src]
```

The `src` parameter is always a list of `Path` objects. `_create_map` must return a list of tuples where the first item of each tuple is the source file and the second item of each tuple is the target file. Both items must be `Path` instances.

If you need additional parameters or different parameter defaults, you have to overwrite the `__init__` method:

```python
import pathlib

class LowercaseMapper(BaseMapper):
    def __init__(self, src, callback, file_dep=False, **kwargs):
        super(LowercaseMapper, self).__init__(
            src, 
            callback, 
            file_dep=file_dep,
            **kwargs
        )

    def _create_map(self, src):
        return [(s, pathlib.Path(str(s).lower())) for s in src]
```

## TODO
- append method for sub_mappers, `__iter__` function for ChainedMapper
- Create specific exceptions
- Add uptodate function to mappers that returns the result of checking timstamps of each source and target file in the map.
- Use [six][6] library for Python 3 compatibility

[1]: http://pydoit.org/ 
[2]: http://ant.apache.org/
[3]: http://www.ruffus.org.uk/
[4]: https://pathlib.readthedocs.org/
[5]: https://docs.python.org/3/library/pathlib.html#concrete-paths
[6]: http://pythonhosted.org/six/
